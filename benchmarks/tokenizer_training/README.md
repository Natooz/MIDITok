# Tokenizer training benchmark

This benchmark aims to measure the training speeds of the different tokenization algorithms, as well as their encoding-decoding speeds, sequence length reduction, and the impact of some other strategies such as spitting the tokens per bars or beats.
